SLX GENERAL PIPELINE FLOW

The General flow of the slx pipeline consists of a couple of steps
(when dealing with slx pipeline, its best to log in as sol-pipe on
 prod-solexa.hgsc.bcm.tmc.edu)

1.  Samples running on the sequencers
    We will receive an email from LIMS about the new incoming runs.
    Update the FcStatus page in TRAC of this new FC.

    The only thing we need to do is to make sure that the images are indeed
    transferring to slxdump.  This is important because the slx instrument 
    will not be able to hold all of data from the sequencer.

    i)   VNC into the slx machines 
           EAS-034: 10.10.59.127:1
           EAS-376: 10.10.59.127:2
    ii)  Check D:\Runs\FC_name
    iii) Check /slxdump2/incoming/FC_name in slxdump
    iv)  Compare and they should be off by 1 or 2 cycles

2.  Raw data (Images) transferring to slxdump
    During the run the images will be transferred to slxdump and when the run
    is complete a file Run.complete will be created and this will indicate the
    final step from the run.

    Be sure that there is enough room on the volume to handle the incoming
    runs.

    36 fragment =~ 850GB
    76 fragment =~ 1.7TB
    36 PE       =~ 1.7TB
    76 PE       =~ 3.3TB

    There is a tool in place which will send out the status of the cycle the
    instrument is on and amount of cycles are left on the machine. If there are
    a large amount of cycles residing on the machine then there may be a problem
    where the robocopy (transferring script from illumina from slx machines to
    sdump) did not transfer data or did not check to remove the data from the
    slx machine.

    There is another C# script thats in place where it will check for percentage
    of disk usage on D:\ of the slx machines.  Once it surpasses the threshold,
    an email will be sent out, indicating that there may be a problem. 
    
    If any of the situations described from above has arised, manual
    transferring of the files from the slx machines to the sdump may be needed.
    This is to ensure that there will be enough room for the raw data that are
    coming off the instruments.

3.  Transferring raw data from slxdump to cluster
    While the sequencer is running and transferring the images to slxdump.  
    Use sdump_clus_#.rb to transfer the data to cluster.  It would be a slow
    turn around time if we wait until the run is completed on the sequencer.
    
    view README.sdump for a more detailed description on sdump_clus_#.rb.

    Be sure that there is enough room on the volume in cluster.
    Remove the images from the previously analyzed runs to free up some space.

    After 12 cycles of phix (lane 5), a QC can be made to check for the phasing
    and prephasing of the run.  Check README.slxpipeline on how to run just one
    lane.  Use 12 cycles while running the goat_generator.  Since there are not
    enough bases for eland (requires at least 32) and a QC step, No alignment 
    is neccessary, Analysis sequence can be used in the GERALD config file.

    When transferring from slxdump to cluster is done, an email will be sent
    from the script.

4.  Remove FC from slxdump
    After the transferring from slxdump to cluster is completed, the transferred
    FC can be removed.
    
    sdump_clus_#.rb has a dry-run in place to make sure all have been 
    transferred.

    If desired, You can run a dry-run again to be sure everything is indeed
    there.

5.  Running of the Analysis
    i)  Create the file structures with goat_generator.sh
    ii) Run the wrapper for slx analysis (created from step i) in goats
    iii)Check the log to confirm no complaints from the wrapper
    iv) Submit the job through the lsf queue
    v)  Check the lsf standard output/error if the anaysis did not finish

    Check README.slxpipeline for a more detail description on how to run the
    anlaysis.

6.  Send Result Summary to LIMS
    i)   After the analysis has completed and a Summary.xml file has been
    generated by the off-line analysis software, cd into the GERALD folder for
    each lane.
    ii)  Run the xmlSummaryParser.rb script.
    iii) Copy the output starting with the perl command to the end of the line
    and paste it on the command line.  Execute each perl command separately.
    iv)  Then confirm that the data has been properly exported by:   
    Openning the following webpage:
    http://10.10.53.190:8080/ngenlims/edu.bcm.hgsc.gwt.lims454.NGenLimsGwt
    /NGenLimsGwt.html
    Then, expanding reports and clicking on Illumina Analysis Run Report.  After
    the page has been loaded, either view the summary results on screen or
    enter the flow cell name into the search field and hit enter.

7.  Mini_anlaysis
    After the summary results have been reported and no more
    altering/reruns will be made to the flow cell, run
    mini_analysis_from_remote.rb to make a copy of the essential files from the
    run.

    Check README.mini_analysis for more information
    
8.  Remove images from cluster
    After the analyses for a flow cell is completed and no more analysis will be
    made, the images from the flow cell can be removed.

    Removing images will able to free up space for the incoming runs. 

9.  Archive data
    Back ups of the analysis needs to be created in order to free up space for
    the new analyses from the incoming runs.

    An backup script from IT is in place, it will look into the file
    /data/archive/slx/archive.queue for paths to backup the data.  Whenever a
    directory is archived the script from IT will add '!' infront of the path.

    Two scripts in $HGSC_SOLID/bin is useful to add the backup path to the
    queue:
    
    add_to_backup_queue.sh - You can either pass in a path you want to back up
    or a list of paths and use the script to add to the end of the
    archive.queue. It also creates a log file with a time stamp in
    ~/.backup/add_log.txt

    check_if_backedup.sh - This script will check the path given with the log
    files to see if the path has been backedup before.

10. Remove data from cluster
    When the back ups are done, the Data directory can be removed while keeping
    the mini_analysis in cluster.
    
    Add the path of the removed directory into ~/.backup/removed.txt to keep
    track of what has been removed.

    A couple of scripts in $HGSC_SOLID/bin can be helpful:
    backup_completed.sh - checks for archived paths in archive.queue and moves
    it to ~/.backup/backup_completed.txt.  It will send out an email to notify
    the users of the archived path.  This script is currenly running at 6:30
    every morning.

    backup_can_be_removed.rb - checks for newly added paths in
    ~/.backup/backup_completed.txt and compares it with
    ~/.backup/removed.txt can creates a file called
    ~/.backup/can_be_removed.txt.  This file holds the paths of the directory
    that have been backedup but still resides in the cluster.

    remove_backedup_paths.sh - takes in a list of directories that are wish to
    be removed, removes the paths, then adds the paths to ~/.backup/removed.txt.


Note:  Be sure to update FcStatus in TRAC on the progress of the flowcell

Besides running the slx flow cell, we should always check on the status of the
volumes.

    http://10.10.59.127/status.txt

This page contains all of the disk usage information on the volumes we use in
cluster.

Each day we should:
  1) check the status of the analyses
  2) check data transfer between instrument and slxdump
  3) check data transfer between slxdump and cluster
  4) check cluster volumes and request for backup or new volumes
